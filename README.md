# Heart Stroke Analysis
### Summary:
In the present days, heart disease and stroke has become the top killers among both women and men. Cardiovascular diseases such as ischaemic heart disease and cerebrovascular such as stroke account for 17.7 million deaths and are the leading cause. In accordance with the World Health Organization, India accounts for one-fifth of these deaths worldwide especially in younger population. 

#### For building a Machine Learning model, the data needs to be preprocessed. The preprocessing of the data includes checking for the presence of the missing observations, outlier detection and feature scaling.  Once the preprocessing is done, we are going to split the data into training and testing. In this case 60% of the data is used for training the model and 40% of the data is used to test the model. We will be using three algorithms i.e., Logistic Regression, Random Forest and XGBoost as they are not sensitive towards the outliers. From the use of confusion matrix and accuracy score, we say that Logistic Regression gives 85.4% accuracy for training data and 84.7% for test data. Whereas, XGBoost gives 98.1% accuracy for training data and 82.6% for test data. Similarly, the accuracy of Random Forest for training data is 99.9% and 84% for test data.  Thus, AUC and ROC curve is used to analyse which of the model best suits in this case. According to AUC and ROC curve Random Forest suits well for training data as it has the highest AUC (i.e., 0.9986) as compaired to other two models (i.e., AUC of Logistic Regression = 0.5187 and AUC of XGBoost = 0.9361). On the other hand, XGBoost suits well for the test data (according to ROC and AUC curve) as it has the highest AUC (i.e., 0.5232) when compaired with the other two models (i.e., AUC of Logistic Regression = 0.5197 and AUC of Random Forest = 0.5177).
Thus we conclude that Random Forest algorithm suits better for the training dataset and XgBoost for the test datsset of the considered data.
